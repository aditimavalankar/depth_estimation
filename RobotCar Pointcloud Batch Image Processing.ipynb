{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.interpolate as interp\n",
    "from scipy.ndimage import map_coordinates\n",
    "import glob\n",
    "\n",
    "from robotcar.python.camera_model import CameraModel\n",
    "from robotcar.python.transform import build_se3_transform\n",
    "from robotcar.python.image import load_image\n",
    "from robotcar.python.interpolate_poses import interpolate_vo_poses, interpolate_ins_poses\n",
    "from robotcar.python.build_pointcloud import build_pointcloud\n",
    "\n",
    "from monodepth.utils.evaluation_utils import compute_errors\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import shutil\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidpointNormalize(colors.Normalize):\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        colors.Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        # I'm ignoring masked values and all kinds of edge cases to make a\n",
    "        # simple example...\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_index_start = 1000\n",
    "img_index_stop = 32000\n",
    "img_index_step = 100\n",
    "\n",
    "# micro!!s history for pointcloud generation\n",
    "time_minus = 8000000\n",
    "time_plus = 0\n",
    "\n",
    "# Width and height of ground truth\n",
    "height = 960\n",
    "width = 1280\n",
    "\n",
    "# Model Maximum and Minimum Prediction Depth (m) --> Taken from Monodepth Paper\n",
    "pred_max = 80\n",
    "pred_min = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = '/media/psf/Data/Downloads/data_test/2014-12-05-11-09-10/2014-12-05-11-09-10_stereo_left/2014-12-05-11-09-10/stereo/left/'\n",
    "extrinsics_dir = 'robotcar/extrinsics/'\n",
    "models_dir = 'robotcar/models/'\n",
    "lidar_dir = '/media/psf/Data/Downloads/data_test/2014-12-05-11-09-10/2014-12-05-11-09-10_ldmrs/ldmrs/'\n",
    "\n",
    "lidar = 'ldmrs'\n",
    "\n",
    "vo_poses_file = '/media/psf/Data/Downloads/data_test/2014-12-05-11-09-10/2014-12-05-11-09-10_vo/vo/vo.csv'\n",
    "ins_poses_file = '/media/psf/Data/Downloads/data_test/2014-12-05-11-09-10/2014-12-05-11-09-10_gps/gps/ins.csv'\n",
    "\n",
    "test_image_dir = 'test_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_disps_to_depths(pred_disps, height, width, pred_max, pred_min):\n",
    "    pred_depths = np.zeros((pred_disps.shape[0],height,width))\n",
    "    for i in range(pred_disps.shape[0]):\n",
    "        # Resize to ground truth shape\n",
    "        pred_disp = width * cv2.resize(pred_disps[i,:,:], (width, height), interpolation=cv2.INTER_LINEAR)\n",
    "        # Convert to depth\n",
    "        pred_depths[i,:,:] = 983.044006 * 0.24 / pred_disp\n",
    "    \n",
    "    # Set 0 for values out of range\n",
    "    # TODO check effect if set to max or min like paper do\n",
    "    pred_depths[((pred_depths > pred_max) | (pred_depths < pred_min))] = 0\n",
    "    \n",
    "    return pred_depths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera and LIDAR Extrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CameraModel(models_dir, image_dir)\n",
    "\n",
    "extrinsics_path = os.path.join(extrinsics_dir, model.camera + '.txt')\n",
    "with open(extrinsics_path) as extrinsics_file:\n",
    "    extrinsics = [float(x) for x in next(extrinsics_file).split(' ')]\n",
    "\n",
    "G_camera_vehicle = build_se3_transform(extrinsics)\n",
    "\n",
    "with open(os.path.join(extrinsics_dir, lidar + '.txt')) as extrinsics_file:\n",
    "    extrinsics = next(extrinsics_file)\n",
    "G_posesource_laser = build_se3_transform([float(x) for x in extrinsics.split(' ')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [RobotCar] Preprocess Images and Save to test folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1 from 310\n",
      "Image 2 from 310\n",
      "Image 3 from 310\n",
      "Image 4 from 310\n",
      "Image 5 from 310\n",
      "Image 6 from 310\n",
      "Image 7 from 310\n",
      "Image 8 from 310\n",
      "Image 9 from 310\n",
      "Image 10 from 310\n",
      "Image 11 from 310\n",
      "Image 12 from 310\n",
      "Image 13 from 310\n",
      "Image 14 from 310\n",
      "Image 15 from 310\n",
      "Image 16 from 310\n",
      "Image 17 from 310\n",
      "Image 18 from 310\n",
      "Image 19 from 310\n",
      "Image 20 from 310\n",
      "Image 21 from 310\n",
      "Image 22 from 310\n",
      "Image 23 from 310\n",
      "Image 24 from 310\n",
      "Image 25 from 310\n",
      "Image 26 from 310\n",
      "Image 27 from 310\n",
      "Image 28 from 310\n",
      "Image 29 from 310\n",
      "Image 30 from 310\n",
      "Image 31 from 310\n",
      "Image 32 from 310\n",
      "Image 33 from 310\n",
      "Image 34 from 310\n",
      "Image 35 from 310\n",
      "Image 36 from 310\n",
      "Image 37 from 310\n",
      "Image 38 from 310\n",
      "Image 39 from 310\n",
      "Image 40 from 310\n",
      "Image 41 from 310\n",
      "Image 42 from 310\n",
      "Image 43 from 310\n",
      "Image 44 from 310\n",
      "Image 45 from 310\n",
      "Image 46 from 310\n",
      "Image 47 from 310\n",
      "Image 48 from 310\n",
      "Image 49 from 310\n",
      "Image 50 from 310\n",
      "Image 51 from 310\n",
      "Image 52 from 310\n",
      "Image 53 from 310\n",
      "Image 54 from 310\n",
      "Image 55 from 310\n",
      "Image 56 from 310\n",
      "Image 57 from 310\n",
      "Image 58 from 310\n",
      "Image 59 from 310\n",
      "Image 60 from 310\n",
      "Image 61 from 310\n",
      "Image 62 from 310\n",
      "Image 63 from 310\n",
      "Image 64 from 310\n",
      "Image 65 from 310\n",
      "Image 66 from 310\n",
      "Image 67 from 310\n",
      "Image 68 from 310\n",
      "Image 69 from 310\n",
      "Image 70 from 310\n",
      "Image 71 from 310\n",
      "Image 72 from 310\n",
      "Image 73 from 310\n",
      "Image 74 from 310\n",
      "Image 75 from 310\n",
      "Image 76 from 310\n",
      "Image 77 from 310\n",
      "Image 78 from 310\n",
      "Image 79 from 310\n",
      "Image 80 from 310\n",
      "Image 81 from 310\n",
      "Image 82 from 310\n",
      "Image 83 from 310\n",
      "Image 84 from 310\n",
      "Image 85 from 310\n",
      "Image 86 from 310\n",
      "Image 87 from 310\n",
      "Image 88 from 310\n",
      "Image 89 from 310\n",
      "Image 90 from 310\n",
      "Image 91 from 310\n",
      "Image 92 from 310\n",
      "Image 93 from 310\n",
      "Image 94 from 310\n",
      "Image 95 from 310\n",
      "Image 96 from 310\n",
      "Image 97 from 310\n",
      "Image 98 from 310\n",
      "Image 99 from 310\n",
      "Image 100 from 310\n",
      "Image 101 from 310\n",
      "Image 102 from 310\n",
      "Image 103 from 310\n",
      "Image 104 from 310\n",
      "Image 105 from 310\n",
      "Image 106 from 310\n",
      "Image 107 from 310\n",
      "Image 108 from 310\n",
      "Image 109 from 310\n",
      "Image 110 from 310\n",
      "Image 111 from 310\n",
      "Image 112 from 310\n",
      "Image 113 from 310\n",
      "Image 114 from 310\n",
      "Image 115 from 310\n",
      "Image 116 from 310\n",
      "Image 117 from 310\n",
      "Image 118 from 310\n",
      "Image 119 from 310\n",
      "Image 120 from 310\n",
      "Image 121 from 310\n",
      "Image 122 from 310\n",
      "Image 123 from 310\n",
      "Image 124 from 310\n",
      "Image 125 from 310\n",
      "Image 126 from 310\n",
      "Image 127 from 310\n",
      "Image 128 from 310\n",
      "Image 129 from 310\n",
      "Image 130 from 310\n",
      "Image 131 from 310\n",
      "Image 132 from 310\n",
      "Image 133 from 310\n",
      "Image 134 from 310\n",
      "Image 135 from 310\n",
      "Image 136 from 310\n",
      "Image 137 from 310\n",
      "Image 138 from 310\n",
      "Image 139 from 310\n",
      "Image 140 from 310\n",
      "Image 141 from 310\n",
      "Image 142 from 310\n",
      "Image 143 from 310\n",
      "Image 144 from 310\n",
      "Image 145 from 310\n",
      "Image 146 from 310\n",
      "Image 147 from 310\n",
      "Image 148 from 310\n",
      "Image 149 from 310\n",
      "Image 150 from 310\n",
      "Image 151 from 310\n",
      "Image 152 from 310\n",
      "Image 153 from 310\n",
      "Image 154 from 310\n",
      "Image 155 from 310\n",
      "Image 156 from 310\n",
      "Image 157 from 310\n",
      "Image 158 from 310\n",
      "Image 159 from 310\n",
      "Image 160 from 310\n",
      "Image 161 from 310\n",
      "Image 162 from 310\n",
      "Image 163 from 310\n",
      "Image 164 from 310\n",
      "Image 165 from 310\n",
      "Image 166 from 310\n",
      "Image 167 from 310\n",
      "Image 168 from 310\n",
      "Image 169 from 310\n",
      "Image 170 from 310\n",
      "Image 171 from 310\n",
      "Image 172 from 310\n",
      "Image 173 from 310\n",
      "Image 174 from 310\n",
      "Image 175 from 310\n",
      "Image 176 from 310\n",
      "Image 177 from 310\n",
      "Image 178 from 310\n",
      "Image 179 from 310\n",
      "Image 180 from 310\n",
      "Image 181 from 310\n",
      "Image 182 from 310\n",
      "Image 183 from 310\n",
      "Image 184 from 310\n",
      "Image 185 from 310\n",
      "Image 186 from 310\n",
      "Image 187 from 310\n",
      "Image 188 from 310\n",
      "Image 189 from 310\n",
      "Image 190 from 310\n",
      "Image 191 from 310\n",
      "Image 192 from 310\n",
      "Image 193 from 310\n",
      "Image 194 from 310\n",
      "Image 195 from 310\n",
      "Image 196 from 310\n",
      "Image 197 from 310\n",
      "Image 198 from 310\n",
      "Image 199 from 310\n",
      "Image 200 from 310\n",
      "Image 201 from 310\n",
      "Image 202 from 310\n",
      "Image 203 from 310\n",
      "Image 204 from 310\n",
      "Image 205 from 310\n",
      "Image 206 from 310\n",
      "Image 207 from 310\n",
      "Image 208 from 310\n",
      "Image 209 from 310\n",
      "Image 210 from 310\n",
      "Image 211 from 310\n",
      "Image 212 from 310\n",
      "Image 213 from 310\n",
      "Image 214 from 310\n",
      "Image 215 from 310\n",
      "Image 216 from 310\n",
      "Image 217 from 310\n",
      "Image 218 from 310\n",
      "Image 219 from 310\n",
      "Image 220 from 310\n",
      "Image 221 from 310\n",
      "Image 222 from 310\n",
      "Image 223 from 310\n",
      "Image 224 from 310\n",
      "Image 225 from 310\n",
      "Image 226 from 310\n",
      "Image 227 from 310\n",
      "Image 228 from 310\n",
      "Image 229 from 310\n",
      "Image 230 from 310\n",
      "Image 231 from 310\n",
      "Image 232 from 310\n",
      "Image 233 from 310\n",
      "Image 234 from 310\n",
      "Image 235 from 310\n",
      "Image 236 from 310\n",
      "Image 237 from 310\n",
      "Image 238 from 310\n",
      "Image 239 from 310\n",
      "Image 240 from 310\n",
      "Image 241 from 310\n",
      "Image 242 from 310\n",
      "Image 243 from 310\n",
      "Image 244 from 310\n",
      "Image 245 from 310\n",
      "Image 246 from 310\n",
      "Image 247 from 310\n",
      "Image 248 from 310\n",
      "Image 249 from 310\n",
      "Image 250 from 310\n",
      "Image 251 from 310\n",
      "Image 252 from 310\n",
      "Image 253 from 310\n",
      "Image 254 from 310\n",
      "Image 255 from 310\n",
      "Image 256 from 310\n",
      "Image 257 from 310\n",
      "Image 258 from 310\n",
      "Image 259 from 310\n",
      "Image 260 from 310\n",
      "Image 261 from 310\n",
      "Image 262 from 310\n",
      "Image 263 from 310\n",
      "Image 264 from 310\n",
      "Image 265 from 310\n",
      "Image 266 from 310\n",
      "Image 267 from 310\n",
      "Image 268 from 310\n",
      "Image 269 from 310\n",
      "Image 270 from 310\n",
      "Image 271 from 310\n",
      "Image 272 from 310\n",
      "Image 273 from 310\n",
      "Image 274 from 310\n",
      "Image 275 from 310\n",
      "Image 276 from 310\n",
      "Image 277 from 310\n",
      "Image 278 from 310\n",
      "Image 279 from 310\n",
      "Image 280 from 310\n",
      "Image 281 from 310\n",
      "Image 282 from 310\n",
      "Image 283 from 310\n",
      "Image 284 from 310\n",
      "Image 285 from 310\n",
      "Image 286 from 310\n",
      "Image 287 from 310\n",
      "Image 288 from 310\n",
      "Image 289 from 310\n",
      "Image 290 from 310\n",
      "Image 291 from 310\n",
      "Image 292 from 310\n",
      "Image 293 from 310\n",
      "Image 294 from 310\n",
      "Image 295 from 310\n",
      "Image 296 from 310\n",
      "Image 297 from 310\n",
      "Image 298 from 310\n",
      "Image 299 from 310\n",
      "Image 300 from 310\n",
      "Image 301 from 310\n",
      "Image 302 from 310\n",
      "Image 303 from 310\n",
      "Image 304 from 310\n",
      "Image 305 from 310\n",
      "Image 306 from 310\n",
      "Image 307 from 310\n",
      "Image 308 from 310\n",
      "Image 309 from 310\n",
      "Image 310 from 310\n"
     ]
    }
   ],
   "source": [
    "# Create/clear test_images folder and create filenames file\n",
    "if os.path.exists(test_image_dir):\n",
    "    shutil.rmtree(test_image_dir) \n",
    "os.makedirs(test_image_dir)\n",
    "\n",
    "with open(test_image_dir + '/test_images.txt', \"a+\") as filenames_file:\n",
    "    \n",
    "    c = 1\n",
    "    for img_index in range(img_index_start, img_index_stop, img_index_step):\n",
    "        print(\"Image {} from {}\".format(c, np.round((img_index_stop-img_index_start)/img_index_step)))\n",
    "        c = c + 1\n",
    "        timestamps_path = os.path.join(image_dir, os.pardir, model.camera + '.timestamps')\n",
    "        if not os.path.isfile(timestamps_path):\n",
    "            timestamps_path = os.path.join(image_dir, os.pardir, os.pardir, model.camera + '.timestamps')\n",
    "\n",
    "        with open(timestamps_path) as timestamps_file:\n",
    "            for i, line in enumerate(timestamps_file):\n",
    "                if i == img_index:\n",
    "                    timestamp_img = int(line.split(' ')[0])\n",
    "\n",
    "        image_path = os.path.join(image_dir, str(timestamp_img) + '.png')\n",
    "        image = load_image(image_path, model)\n",
    "        img = Image.fromarray(image)\n",
    "        img.save('test_images/' + str(timestamp_img) + '.png')\n",
    "\n",
    "        # Append to filenames file\n",
    "        if img_index == img_index_start:\n",
    "            filenames_file.write(str(timestamp_img) + '.png')\n",
    "        else:\n",
    "            filenames_file.write('\\n' + str(timestamp_img) + '.png')\n",
    "filenames_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Monodepth] Get Predictions from Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now testing 310 files\n",
      "step 0 from 310\n",
      "step 1 from 310\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python monodepth/monodepth_main.py --mode test --data_path test_images/ --filenames_file test_images/test_images.txt --log_directory log/ --checkpoint_path monodepth/model_kitti_ft_01/model-1900.ckpt --output_directory test_images/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Monodepth] Convert predicted disparities to depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_disparities_file = 'test_images/disparities_ft.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_disparities = np.load(pred_disparities_file)\n",
    "pred_depths = convert_disps_to_depths(pred_disparities, height, width, pred_max, pred_min)\n",
    "\n",
    "# Convert to dictionary\n",
    "pred_depths_dict = {}\n",
    "i = 0\n",
    "# Loop trough test files\n",
    "for img_file in sorted(glob.glob1(test_image_dir,\"*.png\")):\n",
    "    pred_depths_dict[img_file] = pred_depths[i,:,:]\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [RobotCar] Process Pointclouds and save ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Processing:', '1417778627490633.png')\n",
      "('Processing:', '1417779248343986.png')\n",
      "('Processing:', '1417779808893038.png')\n",
      "('Processing:', '1417777987077821.png')\n",
      "('Processing:', '1417779398386141.png')\n",
      "('Processing:', '1417778897766323.png')\n",
      "('Processing:', '1417777907026267.png')\n",
      "('Processing:', '1417779751775782.png')\n",
      "('Processing:', '1417778343091903.png')\n",
      "('Processing:', '1417778890329826.png')\n",
      "('Processing:', '1417778842648940.png')\n",
      "('Processing:', '1417779628979872.png')\n",
      "('Processing:', '1417779600296312.png')\n",
      "('Processing:', '1417778479260856.png')\n",
      "('Processing:', '1417778128433575.png')\n",
      "('Processing:', '1417778274913692.png')\n",
      "('Processing:', '1417779635291545.png')\n",
      "('Processing:', '1417778180426519.png')\n",
      "('Processing:', '1417779114486972.png')\n",
      "('Processing:', '1417779514182842.png')\n",
      "('Processing:', '1417778735101028.png')\n",
      "('Processing:', '1417778077815558.png')\n",
      "('Processing:', '1417779581548851.png')\n",
      "('Processing:', '1417778261727958.png')\n",
      "('Processing:', '1417778027322445.png')\n",
      "('Processing:', '1417777848971714.png')\n",
      "('Processing:', '1417779319396868.png')\n",
      "('Processing:', '1417778485509953.png')\n",
      "('Processing:', '1417779140671072.png')\n",
      "('Processing:', '1417778459763483.png')\n",
      "('Processing:', '1417779554239991.png')\n",
      "('Processing:', '1417778572997958.png')\n",
      "('Processing:', '1417778441016071.png')\n",
      "('Processing:', '1417779279589690.png')\n",
      "('Processing:', '1417778779282532.png')\n",
      "('Processing:', '1417779185040034.png')\n",
      "('Processing:', '1417779254593145.png')\n",
      "('Processing:', '1417778689982184.png')\n",
      "('Processing:', '1417778186675663.png')\n",
      "('Processing:', '1417777826787255.png')\n",
      "('Processing:', '1417777841722707.png')\n",
      "('Processing:', '1417779024311820.png')\n",
      "('Processing:', '1417779861073513.png')\n",
      "('Processing:', '1417779260842301.png')\n",
      "('Processing:', '1417778161241700.png')\n",
      "('Processing:', '1417778173989825.png')\n",
      "('Processing:', '1417778810528278.png')\n",
      "('Processing:', '1417778065317266.png')\n",
      "('Processing:', '1417779203787484.png')\n",
      "('Processing:', '1417779873696653.png')\n",
      "('Processing:', '1417779566988200.png')\n"
     ]
    }
   ],
   "source": [
    "# Initialize array\n",
    "filecount = len(glob.glob1(test_image_dir,\"*.png\"))\n",
    "# Dictionary\n",
    "# Filename => Height x Width\n",
    "# VO\n",
    "# INS\n",
    "# Local\n",
    "\n",
    "vo_gt_depths = {}\n",
    "ins_gt_depths = {}\n",
    "local_gt_depths = {}\n",
    "    \n",
    "\n",
    "# Loop trough test files\n",
    "for img_file in glob.glob1(test_image_dir,\"*.png\"):\n",
    "    print(\"Processing:\",img_file)\n",
    "    timestamp_img = int(img_file.split('.')[0])\n",
    "\n",
    "    '''\n",
    "    # VO Pointcloud\n",
    "    G_camera_posesource = G_camera_vehicle\n",
    "    \n",
    "    pointcloud, reflectance = build_pointcloud(lidar_dir, vo_poses_file, extrinsics_dir,\n",
    "                                           timestamp_img - time_minus, timestamp_img + time_plus, timestamp_img)\n",
    "    \n",
    "    pointcloud = np.dot(G_camera_posesource, pointcloud)\n",
    "    uv, depth = model.project(pointcloud, (height, width))\n",
    "    uv = np.array(uv)\n",
    "    depth = np.array(depth)\n",
    "    mask = ((uv[0,:] < (width-1)) & (uv[1,:] < (height-1)) & (depth < pred_max) & (depth > pred_min))\n",
    "    depth = depth[mask]\n",
    "    uv = uv[:, mask]\n",
    "    gt_img = np.zeros((height, width))\n",
    "    coords = uv.transpose().astype(int)\n",
    "    gt_img[coords[:,1],coords[:,0]] = depth    \n",
    "    vo_gt_depths[img_file] = gt_img\n",
    "    '''\n",
    "    \n",
    "    # INS Pointcloud\n",
    "    with open(os.path.join(extrinsics_dir, 'ins.txt')) as extrinsics_file:\n",
    "        extrinsics = next(extrinsics_file)\n",
    "        G_camera_posesource = G_camera_vehicle * build_se3_transform([float(x) for x in extrinsics.split(' ')])\n",
    "\n",
    "    pointcloud, reflectance = build_pointcloud(lidar_dir, ins_poses_file, extrinsics_dir,\n",
    "                                           timestamp_img - time_minus, timestamp_img + time_plus, timestamp_img)\n",
    "    pointcloud = np.dot(G_camera_posesource, pointcloud)       \n",
    "    uv, depth = model.project(pointcloud, (height, width))\n",
    "    uv = np.array(uv)\n",
    "    depth = np.array(depth)\n",
    "    mask = ((uv[0,:] < (width-1)) & (uv[1,:] < (height-1)) & (depth < pred_max) & (depth > pred_min))\n",
    "    depth = depth[mask]\n",
    "    uv = uv[:, mask]\n",
    "    gt_img = np.zeros((height, width))\n",
    "    coords = uv.transpose().astype(int)\n",
    "    gt_img[coords[:,1],coords[:,0]] = depth    \n",
    "    ins_gt_depths[img_file] = gt_img    \n",
    "    \n",
    "    # Sparse Local Pointcloud\n",
    "    # Only takes one lidar scan closest to when image was taken\n",
    "    timestamps_path = os.path.join(lidar_dir, os.pardir, lidar + '.timestamps')\n",
    "    with open(timestamps_path) as timestamps_file:\n",
    "        for line in timestamps_file:\n",
    "            this_timestamp = int(line.split(' ')[0])\n",
    "            if this_timestamp >= timestamp_img:\n",
    "                timestamp_lidar = this_timestamp\n",
    "                break\n",
    "    with open(os.path.join(extrinsics_dir, lidar + '.txt')) as extrinsics_file:\n",
    "        extrinsics = next(extrinsics_file)\n",
    "    G_posesource_laser = build_se3_transform([float(x) for x in extrinsics.split(' ')])\n",
    "    local_pointcloud = np.array([[0], [0], [0], [0]])\n",
    "    scan_path = os.path.join(lidar_dir, str(timestamp_lidar) + '.bin')\n",
    "    scan_file = open(scan_path)\n",
    "    scan = np.fromfile(scan_file, np.double)\n",
    "    scan_file.close()\n",
    "    scan = scan.reshape((len(scan) // 3, 3)).transpose()\n",
    "    scan = np.dot(G_posesource_laser, np.vstack([scan, np.ones((1, scan.shape[1]))]))\n",
    "    local_pointcloud = np.hstack([local_pointcloud, scan])\n",
    "    local_pointcloud = local_pointcloud[:, 1:]\n",
    "    local_pointcloud = np.dot(G_camera_vehicle, local_pointcloud)\n",
    "    uv, depth = model.project(local_pointcloud, (height, width))\n",
    "    uv = np.array(uv)\n",
    "    depth = np.array(depth)\n",
    "    mask = ((uv[0,:] < (width-1)) & (uv[1,:] < (height-1)) & (depth < pred_max) & (depth > pred_min))\n",
    "    depth = depth[mask]\n",
    "    uv = uv[:, mask]\n",
    "    gt_img = np.zeros((height, width))\n",
    "    coords = uv.transpose().astype(int)\n",
    "    gt_img[coords[:,1],coords[:,0]] = depth    \n",
    "    local_gt_depths[img_file] = gt_img    \n",
    "    \n",
    "    \n",
    "#np.save(test_image_dir+'/vo_gt_depths.npy', vo_gt_depths)\n",
    "np.save(test_image_dir+'/ins_gt_depths.npy', ins_gt_depths) \n",
    "np.save(test_image_dir+'/local_gt_depths.npy', local_gt_depths) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [RobotCar] Load Ground Truth Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vo_gt_depths = np.load(test_image_dir+'/vo_gt_depths.npy').item()\n",
    "ins_gt_depths = np.load(test_image_dir+'/ins_gt_depths.npy').item()\n",
    "local_gt_depths = np.load(test_image_dir+'/local_gt_depths.npy').item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Test Result with Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filecount = len(glob.glob1(test_image_dir,\"*.png\"))\n",
    "\n",
    "vo_rms     = np.zeros(filecount, np.float32)\n",
    "vo_log_rms = np.zeros(filecount, np.float32)\n",
    "vo_abs_rel = np.zeros(filecount, np.float32)\n",
    "vo_sq_rel  = np.zeros(filecount, np.float32)\n",
    "vo_d1_all  = np.zeros(filecount, np.float32)\n",
    "vo_a1      = np.zeros(filecount, np.float32)\n",
    "vo_a2      = np.zeros(filecount, np.float32)\n",
    "vo_a3      = np.zeros(filecount, np.float32)\n",
    "\n",
    "ins_rms     = np.zeros(filecount, np.float32)\n",
    "ins_log_rms = np.zeros(filecount, np.float32)\n",
    "ins_abs_rel = np.zeros(filecount, np.float32)\n",
    "ins_sq_rel  = np.zeros(filecount, np.float32)\n",
    "ins_d1_all  = np.zeros(filecount, np.float32)\n",
    "ins_a1      = np.zeros(filecount, np.float32)\n",
    "ins_a2      = np.zeros(filecount, np.float32)\n",
    "ins_a3      = np.zeros(filecount, np.float32)\n",
    "\n",
    "local_rms     = np.zeros(filecount, np.float32)\n",
    "local_log_rms = np.zeros(filecount, np.float32)\n",
    "local_abs_rel = np.zeros(filecount, np.float32)\n",
    "local_sq_rel  = np.zeros(filecount, np.float32)\n",
    "local_d1_all  = np.zeros(filecount, np.float32)\n",
    "local_a1      = np.zeros(filecount, np.float32)\n",
    "local_a2      = np.zeros(filecount, np.float32)\n",
    "local_a3      = np.zeros(filecount, np.float32)\n",
    "\n",
    "# Loop trough test files\n",
    "i = 0\n",
    "for img_file in glob.glob1(test_image_dir,\"*.png\"):\n",
    "    vo_abs_rel[i], vo_sq_rel[i], vo_rms[i], vo_log_rms[i], vo_a1[i], vo_a2[i], vo_a3[i] = compute_errors(vo_gt_depths[img_file][vo_gt_depths[img_file] != 0], pred_depths_dict[img_file][vo_gt_depths[img_file] != 0])\n",
    "    ins_abs_rel[i], ins_sq_rel[i], ins_rms[i], ins_log_rms[i], ins_a1[i], ins_a2[i], ins_a3[i] = compute_errors(ins_gt_depths[img_file][ins_gt_depths[img_file] != 0], pred_depths_dict[img_file][ins_gt_depths[img_file] != 0])\n",
    "    local_abs_rel[i], local_sq_rel[i], local_rms[i], local_log_rms[i], local_a1[i], local_a2[i], local_a3[i] = compute_errors(local_gt_depths[img_file][local_gt_depths[img_file] != 0], pred_depths_dict[img_file][local_gt_depths[img_file] != 0])\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}\".format('abs_rel', 'sq_rel', 'rms', 'log_rms', 'd1_all', 'a1', 'a2', 'a3'))\n",
    "print(\"{:10.4f}, {:10.4f}, {:10.3f}, {:10.3f}, {:10.3f}, {:10.3f}, {:10.3f}\".format(local_abs_rel.mean(), local_sq_rel.mean(), local_rms.mean(), local_log_rms.mean(), local_a1.mean(), local_a2.mean(), local_a3.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}\".format('abs_rel', 'sq_rel', 'rms', 'log_rms', 'd1_all', 'a1', 'a2', 'a3'))\n",
    "print(\"{:10.4f}, {:10.4f}, {:10.3f}, {:10.3f}, {:10.3f}, {:10.3f}, {:10.3f}\".format(local_abs_rel.mean(), local_sq_rel.mean(), local_rms.mean(), local_log_rms.mean(), local_a1.mean(), local_a2.mean(), local_a3.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Error Magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(16,20))\n",
    "\n",
    "# Sparse Map\n",
    "ax = plt.subplot(3, 2, 1)\n",
    "ax.set_title(\"Local PC - Pred Error (m) [Pred - GT]\", fontsize=16)\n",
    "uv, depth = model.project(local_pointcloud, image.shape)\n",
    "\n",
    "uv = np.array(uv)\n",
    "depth = np.array(depth)\n",
    "mask = ((uv[0,:] < 1279) & (uv[1,:] < 959) & (depth < 80))\n",
    "depth = depth[mask]\n",
    "uv = uv[:, mask]\n",
    "\n",
    "gt_img = np.zeros((960, 1280))\n",
    "coords = uv.transpose().astype(int)\n",
    "gt_img[coords[:,1],coords[:,0]] = depth\n",
    "compute_errors(gt_img[gt_img != 0], pred_depth[gt_img != 0])\n",
    "abs_rel, sq_rel, rms, log_rms, a1, a2, a3 = compute_errors(gt_img[gt_img != 0], pred_depth[gt_img != 0])\n",
    "print(\"Errors for Local LIDAR:\")\n",
    "print(\"{:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}\".format('abs_rel', 'sq_rel', 'rms', 'log_rms', 'a1', 'a2', 'a3'))\n",
    "print(\"{:10.4f}, {:10.4f}, {:10.3f}, {:10.3f}, {:10.3f}, {:10.3f}, {:10.3f}\".format(abs_rel.mean(), sq_rel.mean(), rms.mean(), log_rms.mean(), a1.mean(), a2.mean(), a3.mean()))\n",
    "\n",
    "pixels = uv.transpose()\n",
    "# 1200 x 960\n",
    "pred_depth_pixels = []\n",
    "pred_depth_error = []\n",
    "i = 0\n",
    "for pixel in pixels:\n",
    "    # Sparse\n",
    "    pred_depth_pixels.append(pred_depth[int(round(pixel[1]))][int(round(pixel[0]))])\n",
    "    pred_depth_error.append(pred_depth[int(round(pixel[1]))][int(round(pixel[0]))] - depth[i])\n",
    "    i += 1\n",
    "\n",
    "# Limit coordinates to image size\n",
    "pred_depth_pixels = np.array(pred_depth_pixels)\n",
    "pred_depth_error = np.array(pred_depth_error)\n",
    "mask = (pred_depth_pixels < 80)\n",
    "depth = depth[mask]\n",
    "uv = uv[:, mask]\n",
    "pred_depth_error = pred_depth_error[mask]\n",
    "pred_depth_pixels = pred_depth_pixels[mask]\n",
    "    \n",
    "plt.imshow(image)\n",
    "plt.hold(True)\n",
    "sc = plt.scatter(np.ravel(uv[0, :]), np.ravel(uv[1, :]), s=20, c=pred_depth_error,\n",
    "                 edgecolors='none', norm=MidpointNormalize(midpoint=0.) , cmap='RdYlGn')\n",
    "plt.colorbar(sc)\n",
    "plt.xlim(0, image.shape[1])\n",
    "plt.ylim(image.shape[0], 0)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "ax = plt.subplot(3, 2, 2)\n",
    "ax.set_title(\"Local PC - Pred Error (Rel. Mag.) [Pred - GT]\", fontsize=16)\n",
    "plt.imshow(image)\n",
    "plt.hold(True)\n",
    "sc = plt.scatter(np.ravel(uv[0, :]), np.ravel(uv[1, :]), s=20, c=np.abs(pred_depth_error/depth),\n",
    "                 edgecolors='none', cmap='Reds')\n",
    "plt.colorbar(sc)\n",
    "plt.xlim(0, image.shape[1])\n",
    "plt.ylim(image.shape[0], 0)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "ax = plt.subplot(3, 2, 3)\n",
    "ax.set_title(\"VO PC - Pred Error (m) [Pred - GT]\", fontsize=16)\n",
    "uv, depth = model.project(pointcloud_vo, image.shape)\n",
    "\n",
    "# Limit coordinates to image size\n",
    "uv = np.array(uv)\n",
    "depth = np.array(depth)\n",
    "mask = ((uv[0,:] < 1279) & (uv[1,:] < 959) & (depth < 80))\n",
    "depth = depth[mask]\n",
    "uv = uv[:, mask]\n",
    "\n",
    "gt_img = np.zeros((960, 1280))\n",
    "coords = uv.transpose().astype(int)\n",
    "gt_img[coords[:,1],coords[:,0]] = depth\n",
    "compute_errors(gt_img[gt_img != 0], pred_depth[gt_img != 0])\n",
    "abs_rel, sq_rel, rms, log_rms, a1, a2, a3 = compute_errors(gt_img[gt_img != 0], pred_depth[gt_img != 0])\n",
    "print(\"Errors for INS LIDAR:\")\n",
    "print(\"{:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}\".format('abs_rel', 'sq_rel', 'rms', 'log_rms', 'a1', 'a2', 'a3'))\n",
    "print(\"{:10.4f}, {:10.4f}, {:10.3f}, {:10.3f}, {:10.3f}, {:10.3f}, {:10.3f}\".format(abs_rel.mean(), sq_rel.mean(), rms.mean(), log_rms.mean(), a1.mean(), a2.mean(), a3.mean()))\n",
    "\n",
    "pixels = uv.transpose()\n",
    "# 1200 x 960\n",
    "pred_depth_pixels = []\n",
    "pred_depth_error = []\n",
    "i = 0\n",
    "for pixel in pixels:\n",
    "    # Sparse\n",
    "    pred_depth_pixels.append(pred_depth[int(round(pixel[1]))][int(round(pixel[0]))])\n",
    "    pred_depth_error.append(pred_depth[int(round(pixel[1]))][int(round(pixel[0]))] - depth[i])\n",
    "    i += 1\n",
    "\n",
    "# Limit coordinates to image size\n",
    "pred_depth_pixels = np.array(pred_depth_pixels)\n",
    "pred_depth_error = np.array(pred_depth_error)\n",
    "mask = (pred_depth_pixels < 80)\n",
    "depth = depth[mask]\n",
    "uv = uv[:, mask]\n",
    "pred_depth_error = pred_depth_error[mask]\n",
    "pred_depth_pixels = pred_depth_pixels[mask]\n",
    "    \n",
    "plt.imshow(image)\n",
    "plt.hold(True)\n",
    "sc = plt.scatter(np.ravel(uv[0, :]), np.ravel(uv[1, :]), s=20, c=pred_depth_error, norm=MidpointNormalize(midpoint=0.), cmap='RdYlGn',\n",
    "                 edgecolors='none')\n",
    "plt.colorbar(sc)\n",
    "plt.xlim(0, image.shape[1])\n",
    "plt.ylim(image.shape[0], 0)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "ax = plt.subplot(3, 2, 4)\n",
    "ax.set_title(\"VO PC - Pred Error (Rel. Mag.) [Pred - GT]\", fontsize=16)\n",
    "plt.imshow(image)\n",
    "plt.hold(True)\n",
    "sc = plt.scatter(np.ravel(uv[0, :]), np.ravel(uv[1, :]), s=20, c=np.abs(pred_depth_error/depth),\n",
    "                 edgecolors='none', cmap='Reds')\n",
    "plt.colorbar(sc)\n",
    "plt.xlim(0, image.shape[1])\n",
    "plt.ylim(image.shape[0], 0)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "ax = plt.subplot(3, 2, 5)\n",
    "ax.set_title(\"INS PC - Pred Error (m) [Pred - GT]\", fontsize=16)\n",
    "uv, depth = model.project(pointcloud_ins, image.shape)\n",
    "\n",
    "# Limit coordinates to image size\n",
    "uv = np.array(uv)\n",
    "depth = np.array(depth)\n",
    "mask = ((uv[0,:] < 1279) & (uv[1,:] < 959) & (depth < 80))\n",
    "depth = depth[mask]\n",
    "uv = uv[:, mask]\n",
    "\n",
    "gt_img = np.zeros((960, 1280))\n",
    "coords = uv.transpose().astype(int)\n",
    "gt_img[coords[:,1],coords[:,0]] = depth\n",
    "compute_errors(gt_img[gt_img != 0], pred_depth[gt_img != 0])\n",
    "abs_rel, sq_rel, rms, log_rms, a1, a2, a3 = compute_errors(gt_img[gt_img != 0], pred_depth[gt_img != 0])\n",
    "print(\"Errors for VO LIDAR:\")\n",
    "print(\"{:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}\".format('abs_rel', 'sq_rel', 'rms', 'log_rms', 'a1', 'a2', 'a3'))\n",
    "print(\"{:10.4f}, {:10.4f}, {:10.3f}, {:10.3f}, {:10.3f}, {:10.3f}, {:10.3f}\".format(abs_rel.mean(), sq_rel.mean(), rms.mean(), log_rms.mean(), a1.mean(), a2.mean(), a3.mean()))\n",
    "\n",
    "pixels = uv.transpose()\n",
    "# 1200 x 960\n",
    "pred_depth_pixels = []\n",
    "pred_depth_error = []\n",
    "i = 0\n",
    "for pixel in pixels:\n",
    "    # Sparse\n",
    "    pred_depth_pixels.append(pred_depth[int(round(pixel[1]))][int(round(pixel[0]))])\n",
    "    pred_depth_error.append(pred_depth[int(round(pixel[1]))][int(round(pixel[0]))] - depth[i])\n",
    "    i += 1\n",
    "\n",
    "# Limit coordinates to image size\n",
    "pred_depth_pixels = np.array(pred_depth_pixels)\n",
    "pred_depth_error = np.array(pred_depth_error)\n",
    "mask = (pred_depth_pixels < 80)\n",
    "depth = depth[mask]\n",
    "uv = uv[:, mask]\n",
    "pred_depth_error = pred_depth_error[mask]\n",
    "pred_depth_pixels = pred_depth_pixels[mask]\n",
    "    \n",
    "plt.imshow(image)\n",
    "plt.hold(True)\n",
    "sc = plt.scatter(np.ravel(uv[0, :]), np.ravel(uv[1, :]), s=20, c=pred_depth_error, edgecolors='none', norm=MidpointNormalize(midpoint=0.), cmap='RdYlGn')\n",
    "plt.colorbar(sc)\n",
    "plt.xlim(0, image.shape[1])\n",
    "plt.ylim(image.shape[0], 0)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "ax = plt.subplot(3, 2, 6)\n",
    "ax.set_title(\"INS PC - Pred Error (Rel. Mag.) [Pred - GT]\", fontsize=16)\n",
    "plt.imshow(image)\n",
    "plt.hold(True)\n",
    "sc = plt.scatter(np.ravel(uv[0, :]), np.ravel(uv[1, :]), s=20, c=np.abs(pred_depth_error/depth),\n",
    "                 edgecolors='none', cmap='Reds')\n",
    "plt.colorbar(sc)\n",
    "plt.xlim(0, image.shape[1])\n",
    "plt.ylim(image.shape[0], 0)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.savefig('result_imgs/' + str(timestamp_img) + 'results.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
