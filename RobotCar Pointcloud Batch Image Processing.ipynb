{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.interpolate as interp\n",
    "from scipy.ndimage import map_coordinates\n",
    "import glob\n",
    "\n",
    "from robotcar.python.camera_model import CameraModel\n",
    "from robotcar.python.transform import build_se3_transform\n",
    "from robotcar.python.image import load_image\n",
    "from robotcar.python.interpolate_poses import interpolate_vo_poses, interpolate_ins_poses\n",
    "from robotcar.python.build_pointcloud import build_pointcloud\n",
    "\n",
    "from monodepth.utils.evaluation_utils import compute_errors\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import shutil\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidpointNormalize(colors.Normalize):\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        colors.Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        # I'm ignoring masked values and all kinds of edge cases to make a\n",
    "        # simple example...\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_index_start = 10050\n",
    "img_index_stop = 12000\n",
    "img_index_step = 100\n",
    "\n",
    "# micro!!s history for pointcloud generation\n",
    "time_minus = 10000000\n",
    "time_plus = 0\n",
    "\n",
    "# Width and height of ground truth\n",
    "height = 960\n",
    "width = 1280\n",
    "\n",
    "# Model Maximum and Minimum Prediction Depth (m) --> Taken from Monodepth Paper\n",
    "pred_max = 80\n",
    "pred_min = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = '/media/psf/Data/Downloads/2014-12-05-11-09-10/2014-12-05-11-09-10_stereo_left_02/2014-12-05-11-09-10/stereo/left/'\n",
    "extrinsics_dir = 'robotcar/extrinsics/'\n",
    "models_dir = 'robotcar/models/'\n",
    "lidar_dir = '/media/psf/Data/Downloads/2014-12-05-11-09-10/2014-12-05-11-09-10_ldmrs/ldmrs/'\n",
    "\n",
    "lidar = 'ldmrs'\n",
    "\n",
    "vo_poses_file = '/media/psf/Data/Downloads/2014-12-05-11-09-10/2014-12-05-11-09-10_vo/vo/vo.csv'\n",
    "ins_poses_file = '/media/psf/Data/Downloads/2014-12-05-11-09-10/2014-12-05-11-09-10_gps/gps/ins.csv'\n",
    "\n",
    "test_image_dir = 'test_images'\n",
    "\n",
    "pred_disparities_file = 'test_images/disparities.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_disps_to_depths(pred_disps, height, width, pred_max, pred_min):\n",
    "    pred_depths = np.zeros((pred_disps.shape[0],height,width))\n",
    "    for i in range(pred_disps.shape[0]):\n",
    "        # Resize to ground truth shape\n",
    "        pred_disp = width * cv2.resize(pred_disps[i,:,:], (width, height), interpolation=cv2.INTER_LINEAR)\n",
    "        # Convert to depth\n",
    "        pred_depths[i,:,:] = 983.044006 * 0.24 / pred_disp\n",
    "    \n",
    "    # Set 0 for values out of range\n",
    "    # TODO check effect if set to max or min like paper do\n",
    "    pred_depths[((pred_depths > pred_max) | (pred_depths < pred_min))] = 0\n",
    "    \n",
    "    return pred_depths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera and LIDAR Extrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CameraModel(models_dir, image_dir)\n",
    "\n",
    "extrinsics_path = os.path.join(extrinsics_dir, model.camera + '.txt')\n",
    "with open(extrinsics_path) as extrinsics_file:\n",
    "    extrinsics = [float(x) for x in next(extrinsics_file).split(' ')]\n",
    "\n",
    "G_camera_vehicle = build_se3_transform(extrinsics)\n",
    "\n",
    "with open(os.path.join(extrinsics_dir, lidar + '.txt')) as extrinsics_file:\n",
    "    extrinsics = next(extrinsics_file)\n",
    "G_posesource_laser = build_se3_transform([float(x) for x in extrinsics.split(' ')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [RobotCar] Preprocess Images and Save to test folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create/clear test_images folder and create filenames file\n",
    "if os.path.exists(test_image_dir):\n",
    "    shutil.rmtree(test_image_dir) \n",
    "os.makedirs(test_image_dir)\n",
    "\n",
    "with open(test_image_dir + '/test_images.txt', \"a+\") as filenames_file:\n",
    "    \n",
    "    for img_index in range(img_index_start, img_index_stop, img_index_step):\n",
    "        timestamps_path = os.path.join(image_dir, os.pardir, model.camera + '.timestamps')\n",
    "        if not os.path.isfile(timestamps_path):\n",
    "            timestamps_path = os.path.join(image_dir, os.pardir, os.pardir, model.camera + '.timestamps')\n",
    "\n",
    "        with open(timestamps_path) as timestamps_file:\n",
    "            for i, line in enumerate(timestamps_file):\n",
    "                if i == img_index:\n",
    "                    timestamp_img = int(line.split(' ')[0])\n",
    "\n",
    "        image_path = os.path.join(image_dir, str(timestamp_img) + '.png')\n",
    "        image = load_image(image_path, model)\n",
    "        img = Image.fromarray(image)\n",
    "        img.save('test_images/' + str(timestamp_img) + '.png')\n",
    "\n",
    "        # Append to filenames file\n",
    "        if img_index == img_index_start:\n",
    "            filenames_file.write(str(timestamp_img) + '.png')\n",
    "        else:\n",
    "            filenames_file.write('\\n' + str(timestamp_img) + '.png')\n",
    "filenames_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Monodepth] Get Predictions from Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now testing 20 files\n",
      "step 0 from 20\n",
      "step 1 from 20\n",
      "step 2 from 20\n",
      "step 3 from 20\n",
      "step 4 from 20\n",
      "step 5 from 20\n",
      "step 6 from 20\n",
      "step 7 from 20\n",
      "step 8 from 20\n",
      "step 9 from 20\n",
      "step 10 from 20\n",
      "step 11 from 20\n",
      "step 12 from 20\n",
      "step 13 from 20\n",
      "step 14 from 20\n",
      "step 15 from 20\n",
      "step 16 from 20\n",
      "step 17 from 20\n",
      "step 18 from 20\n",
      "step 19 from 20\n",
      "done.\n",
      "writing disparities.\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "!python monodepth/monodepth_main.py --mode test --data_path test_images/ --filenames_file test_images/test_images.txt --log_directory log/ --checkpoint_path monodepth/model_kitti/model_kitti.ckpt --output_directory test_images/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Monodepth] Convert predicted disparities to depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_disparities = np.load(pred_disparities_file)\n",
    "pred_depths = convert_disps_to_depths(pred_disparities, height, width, pred_max, pred_min)\n",
    "\n",
    "# Convert to dictionary\n",
    "pred_depths_dict = {}\n",
    "i = 0\n",
    "# Loop trough test files\n",
    "for img_file in sorted(glob.glob1(test_image_dir,\"*.png\")):\n",
    "    pred_depths_dict[img_file] = pred_depths[i,:,:]\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [RobotCar] Process Pointclouds and save ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Processing:', '1417778534003318.png')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "robotcar/python/interpolate_poses.py:141: RuntimeWarning: divide by zero encountered in divide\n",
      "  (pose_timestamps[upper_indices] - pose_timestamps[lower_indices])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Processing:', '1417778540377431.png')\n",
      "('Processing:', '1417778494883659.png')\n",
      "('Processing:', '1417778547813893.png')\n",
      "('Processing:', '1417778462888098.png')\n",
      "('Processing:', '1417778450389783.png')\n",
      "('Processing:', '1417778520817583.png')\n",
      "('Processing:', '1417778527254246.png')\n",
      "('Processing:', '1417778501132864.png')\n",
      "('Processing:', '1417778444140655.png')\n",
      "('Processing:', '1417778514381060.png')\n",
      "('Processing:', '1417778507756833.png')\n",
      "('Processing:', '1417778476136297.png')\n",
      "('Processing:', '1417778437891432.png')\n",
      "('Processing:', '1417778488634567.png')\n",
      "('Processing:', '1417778554375554.png')\n",
      "('Processing:', '1417778456638951.png')\n",
      "('Processing:', '1417778482385444.png')\n",
      "('Processing:', '1417778469137100.png')\n",
      "('Processing:', '1417778561499529.png')\n"
     ]
    }
   ],
   "source": [
    "# Initialize array\n",
    "filecount = len(glob.glob1(test_image_dir,\"*.png\"))\n",
    "# Dictionary\n",
    "# Filename => Height x Width\n",
    "# VO\n",
    "# INS\n",
    "# Local\n",
    "\n",
    "vo_gt_depths = {}\n",
    "ins_gt_depths = {}\n",
    "local_gt_depths = {}\n",
    "    \n",
    "\n",
    "# Loop trough test files\n",
    "for img_file in glob.glob1(test_image_dir,\"*.png\"):\n",
    "    print(\"Processing:\",img_file)\n",
    "    timestamp_img = int(img_file.split('.')[0])\n",
    "\n",
    "\n",
    "    # VO Pointcloud\n",
    "    G_camera_posesource = G_camera_vehicle\n",
    "    \n",
    "    pointcloud, reflectance = build_pointcloud(lidar_dir, vo_poses_file, extrinsics_dir,\n",
    "                                           timestamp_img - time_minus, timestamp_img + time_plus, timestamp_img)\n",
    "    \n",
    "    pointcloud = np.dot(G_camera_posesource, pointcloud)\n",
    "    uv, depth = model.project(pointcloud, (height, width))\n",
    "    uv = np.array(uv)\n",
    "    depth = np.array(depth)\n",
    "    mask = ((uv[0,:] < (width-1)) & (uv[1,:] < (height-1)) & (depth < pred_max) & (depth > pred_min))\n",
    "    depth = depth[mask]\n",
    "    uv = uv[:, mask]\n",
    "    gt_img = np.zeros((height, width))\n",
    "    coords = uv.transpose().astype(int)\n",
    "    gt_img[coords[:,1],coords[:,0]] = depth    \n",
    "    vo_gt_depths[img_file] = gt_img\n",
    "    \n",
    "    # INS Pointcloud\n",
    "    with open(os.path.join(extrinsics_dir, 'ins.txt')) as extrinsics_file:\n",
    "        extrinsics = next(extrinsics_file)\n",
    "        G_camera_posesource = G_camera_vehicle * build_se3_transform([float(x) for x in extrinsics.split(' ')])\n",
    "\n",
    "    pointcloud, reflectance = build_pointcloud(lidar_dir, ins_poses_file, extrinsics_dir,\n",
    "                                           timestamp_img - time_minus, timestamp_img + time_plus, timestamp_img)\n",
    "    pointcloud = np.dot(G_camera_posesource, pointcloud)       \n",
    "    uv, depth = model.project(pointcloud, (height, width))\n",
    "    uv = np.array(uv)\n",
    "    depth = np.array(depth)\n",
    "    mask = ((uv[0,:] < (width-1)) & (uv[1,:] < (height-1)) & (depth < pred_max) & (depth > pred_min))\n",
    "    depth = depth[mask]\n",
    "    uv = uv[:, mask]\n",
    "    gt_img = np.zeros((height, width))\n",
    "    coords = uv.transpose().astype(int)\n",
    "    gt_img[coords[:,1],coords[:,0]] = depth    \n",
    "    ins_gt_depths[img_file] = gt_img    \n",
    "    \n",
    "    # Sparse Local Pointcloud\n",
    "    # Only takes one lidar scan closest to when image was taken\n",
    "    timestamps_path = os.path.join(lidar_dir, os.pardir, lidar + '.timestamps')\n",
    "    with open(timestamps_path) as timestamps_file:\n",
    "        for line in timestamps_file:\n",
    "            this_timestamp = int(line.split(' ')[0])\n",
    "            if this_timestamp >= timestamp_img:\n",
    "                timestamp_lidar = this_timestamp\n",
    "                break\n",
    "    with open(os.path.join(extrinsics_dir, lidar + '.txt')) as extrinsics_file:\n",
    "        extrinsics = next(extrinsics_file)\n",
    "    G_posesource_laser = build_se3_transform([float(x) for x in extrinsics.split(' ')])\n",
    "    local_pointcloud = np.array([[0], [0], [0], [0]])\n",
    "    scan_path = os.path.join(lidar_dir, str(timestamp_lidar) + '.bin')\n",
    "    scan_file = open(scan_path)\n",
    "    scan = np.fromfile(scan_file, np.double)\n",
    "    scan_file.close()\n",
    "    scan = scan.reshape((len(scan) // 3, 3)).transpose()\n",
    "    scan = np.dot(G_posesource_laser, np.vstack([scan, np.ones((1, scan.shape[1]))]))\n",
    "    local_pointcloud = np.hstack([local_pointcloud, scan])\n",
    "    local_pointcloud = local_pointcloud[:, 1:]\n",
    "    local_pointcloud = np.dot(G_camera_vehicle, local_pointcloud)\n",
    "    uv, depth = model.project(local_pointcloud, (height, width))\n",
    "    uv = np.array(uv)\n",
    "    depth = np.array(depth)\n",
    "    mask = ((uv[0,:] < (width-1)) & (uv[1,:] < (height-1)) & (depth < pred_max) & (depth > pred_min))\n",
    "    depth = depth[mask]\n",
    "    uv = uv[:, mask]\n",
    "    gt_img = np.zeros((height, width))\n",
    "    coords = uv.transpose().astype(int)\n",
    "    gt_img[coords[:,1],coords[:,0]] = depth    \n",
    "    local_gt_depths[img_file] = gt_img    \n",
    "    \n",
    "    \n",
    "np.save(test_image_dir+'/vo_gt_depths.npy', vo_gt_depths)\n",
    "np.save(test_image_dir+'/ins_gt_depths.npy', ins_gt_depths) \n",
    "np.save(test_image_dir+'/local_gt_depths.npy', local_gt_depths) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [RobotCar] Load Ground Truth Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vo_gt_depths = np.load(test_image_dir+'/vo_gt_depths.npy').item()\n",
    "ins_gt_depths = np.load(test_image_dir+'/ins_gt_depths.npy').item()\n",
    "local_gt_depths = np.load(test_image_dir+'/local_gt_depths.npy').item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Test Result with Ground Truth\n",
    "## TODO implement for multiple images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Error Magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(16,20))\n",
    "\n",
    "# Sparse Map\n",
    "ax = plt.subplot(3, 2, 1)\n",
    "ax.set_title(\"Local PC - Pred Error (m) [Pred - GT]\", fontsize=16)\n",
    "uv, depth = model.project(local_pointcloud, image.shape)\n",
    "\n",
    "uv = np.array(uv)\n",
    "depth = np.array(depth)\n",
    "mask = ((uv[0,:] < 1279) & (uv[1,:] < 959) & (depth < 80))\n",
    "depth = depth[mask]\n",
    "uv = uv[:, mask]\n",
    "\n",
    "gt_img = np.zeros((960, 1280))\n",
    "coords = uv.transpose().astype(int)\n",
    "gt_img[coords[:,1],coords[:,0]] = depth\n",
    "compute_errors(gt_img[gt_img != 0], pred_depth[gt_img != 0])\n",
    "abs_rel, sq_rel, rms, log_rms, a1, a2, a3 = compute_errors(gt_img[gt_img != 0], pred_depth[gt_img != 0])\n",
    "print(\"Errors for Local LIDAR:\")\n",
    "print(\"{:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}\".format('abs_rel', 'sq_rel', 'rms', 'log_rms', 'a1', 'a2', 'a3'))\n",
    "print(\"{:10.4f}, {:10.4f}, {:10.3f}, {:10.3f}, {:10.3f}, {:10.3f}, {:10.3f}\".format(abs_rel.mean(), sq_rel.mean(), rms.mean(), log_rms.mean(), a1.mean(), a2.mean(), a3.mean()))\n",
    "\n",
    "pixels = uv.transpose()\n",
    "# 1200 x 960\n",
    "pred_depth_pixels = []\n",
    "pred_depth_error = []\n",
    "i = 0\n",
    "for pixel in pixels:\n",
    "    # Sparse\n",
    "    pred_depth_pixels.append(pred_depth[int(round(pixel[1]))][int(round(pixel[0]))])\n",
    "    pred_depth_error.append(pred_depth[int(round(pixel[1]))][int(round(pixel[0]))] - depth[i])\n",
    "    i += 1\n",
    "\n",
    "# Limit coordinates to image size\n",
    "pred_depth_pixels = np.array(pred_depth_pixels)\n",
    "pred_depth_error = np.array(pred_depth_error)\n",
    "mask = (pred_depth_pixels < 80)\n",
    "depth = depth[mask]\n",
    "uv = uv[:, mask]\n",
    "pred_depth_error = pred_depth_error[mask]\n",
    "pred_depth_pixels = pred_depth_pixels[mask]\n",
    "    \n",
    "plt.imshow(image)\n",
    "plt.hold(True)\n",
    "sc = plt.scatter(np.ravel(uv[0, :]), np.ravel(uv[1, :]), s=20, c=pred_depth_error,\n",
    "                 edgecolors='none', norm=MidpointNormalize(midpoint=0.) , cmap='RdYlGn')\n",
    "plt.colorbar(sc)\n",
    "plt.xlim(0, image.shape[1])\n",
    "plt.ylim(image.shape[0], 0)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "ax = plt.subplot(3, 2, 2)\n",
    "ax.set_title(\"Local PC - Pred Error (Rel. Mag.) [Pred - GT]\", fontsize=16)\n",
    "plt.imshow(image)\n",
    "plt.hold(True)\n",
    "sc = plt.scatter(np.ravel(uv[0, :]), np.ravel(uv[1, :]), s=20, c=np.abs(pred_depth_error/depth),\n",
    "                 edgecolors='none', cmap='Reds')\n",
    "plt.colorbar(sc)\n",
    "plt.xlim(0, image.shape[1])\n",
    "plt.ylim(image.shape[0], 0)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "ax = plt.subplot(3, 2, 3)\n",
    "ax.set_title(\"VO PC - Pred Error (m) [Pred - GT]\", fontsize=16)\n",
    "uv, depth = model.project(pointcloud_vo, image.shape)\n",
    "\n",
    "# Limit coordinates to image size\n",
    "uv = np.array(uv)\n",
    "depth = np.array(depth)\n",
    "mask = ((uv[0,:] < 1279) & (uv[1,:] < 959) & (depth < 80))\n",
    "depth = depth[mask]\n",
    "uv = uv[:, mask]\n",
    "\n",
    "gt_img = np.zeros((960, 1280))\n",
    "coords = uv.transpose().astype(int)\n",
    "gt_img[coords[:,1],coords[:,0]] = depth\n",
    "compute_errors(gt_img[gt_img != 0], pred_depth[gt_img != 0])\n",
    "abs_rel, sq_rel, rms, log_rms, a1, a2, a3 = compute_errors(gt_img[gt_img != 0], pred_depth[gt_img != 0])\n",
    "print(\"Errors for INS LIDAR:\")\n",
    "print(\"{:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}\".format('abs_rel', 'sq_rel', 'rms', 'log_rms', 'a1', 'a2', 'a3'))\n",
    "print(\"{:10.4f}, {:10.4f}, {:10.3f}, {:10.3f}, {:10.3f}, {:10.3f}, {:10.3f}\".format(abs_rel.mean(), sq_rel.mean(), rms.mean(), log_rms.mean(), a1.mean(), a2.mean(), a3.mean()))\n",
    "\n",
    "pixels = uv.transpose()\n",
    "# 1200 x 960\n",
    "pred_depth_pixels = []\n",
    "pred_depth_error = []\n",
    "i = 0\n",
    "for pixel in pixels:\n",
    "    # Sparse\n",
    "    pred_depth_pixels.append(pred_depth[int(round(pixel[1]))][int(round(pixel[0]))])\n",
    "    pred_depth_error.append(pred_depth[int(round(pixel[1]))][int(round(pixel[0]))] - depth[i])\n",
    "    i += 1\n",
    "\n",
    "# Limit coordinates to image size\n",
    "pred_depth_pixels = np.array(pred_depth_pixels)\n",
    "pred_depth_error = np.array(pred_depth_error)\n",
    "mask = (pred_depth_pixels < 80)\n",
    "depth = depth[mask]\n",
    "uv = uv[:, mask]\n",
    "pred_depth_error = pred_depth_error[mask]\n",
    "pred_depth_pixels = pred_depth_pixels[mask]\n",
    "    \n",
    "plt.imshow(image)\n",
    "plt.hold(True)\n",
    "sc = plt.scatter(np.ravel(uv[0, :]), np.ravel(uv[1, :]), s=20, c=pred_depth_error, norm=MidpointNormalize(midpoint=0.), cmap='RdYlGn',\n",
    "                 edgecolors='none')\n",
    "plt.colorbar(sc)\n",
    "plt.xlim(0, image.shape[1])\n",
    "plt.ylim(image.shape[0], 0)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "ax = plt.subplot(3, 2, 4)\n",
    "ax.set_title(\"VO PC - Pred Error (Rel. Mag.) [Pred - GT]\", fontsize=16)\n",
    "plt.imshow(image)\n",
    "plt.hold(True)\n",
    "sc = plt.scatter(np.ravel(uv[0, :]), np.ravel(uv[1, :]), s=20, c=np.abs(pred_depth_error/depth),\n",
    "                 edgecolors='none', cmap='Reds')\n",
    "plt.colorbar(sc)\n",
    "plt.xlim(0, image.shape[1])\n",
    "plt.ylim(image.shape[0], 0)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "ax = plt.subplot(3, 2, 5)\n",
    "ax.set_title(\"INS PC - Pred Error (m) [Pred - GT]\", fontsize=16)\n",
    "uv, depth = model.project(pointcloud_ins, image.shape)\n",
    "\n",
    "# Limit coordinates to image size\n",
    "uv = np.array(uv)\n",
    "depth = np.array(depth)\n",
    "mask = ((uv[0,:] < 1279) & (uv[1,:] < 959) & (depth < 80))\n",
    "depth = depth[mask]\n",
    "uv = uv[:, mask]\n",
    "\n",
    "gt_img = np.zeros((960, 1280))\n",
    "coords = uv.transpose().astype(int)\n",
    "gt_img[coords[:,1],coords[:,0]] = depth\n",
    "compute_errors(gt_img[gt_img != 0], pred_depth[gt_img != 0])\n",
    "abs_rel, sq_rel, rms, log_rms, a1, a2, a3 = compute_errors(gt_img[gt_img != 0], pred_depth[gt_img != 0])\n",
    "print(\"Errors for VO LIDAR:\")\n",
    "print(\"{:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}\".format('abs_rel', 'sq_rel', 'rms', 'log_rms', 'a1', 'a2', 'a3'))\n",
    "print(\"{:10.4f}, {:10.4f}, {:10.3f}, {:10.3f}, {:10.3f}, {:10.3f}, {:10.3f}\".format(abs_rel.mean(), sq_rel.mean(), rms.mean(), log_rms.mean(), a1.mean(), a2.mean(), a3.mean()))\n",
    "\n",
    "pixels = uv.transpose()\n",
    "# 1200 x 960\n",
    "pred_depth_pixels = []\n",
    "pred_depth_error = []\n",
    "i = 0\n",
    "for pixel in pixels:\n",
    "    # Sparse\n",
    "    pred_depth_pixels.append(pred_depth[int(round(pixel[1]))][int(round(pixel[0]))])\n",
    "    pred_depth_error.append(pred_depth[int(round(pixel[1]))][int(round(pixel[0]))] - depth[i])\n",
    "    i += 1\n",
    "\n",
    "# Limit coordinates to image size\n",
    "pred_depth_pixels = np.array(pred_depth_pixels)\n",
    "pred_depth_error = np.array(pred_depth_error)\n",
    "mask = (pred_depth_pixels < 80)\n",
    "depth = depth[mask]\n",
    "uv = uv[:, mask]\n",
    "pred_depth_error = pred_depth_error[mask]\n",
    "pred_depth_pixels = pred_depth_pixels[mask]\n",
    "    \n",
    "plt.imshow(image)\n",
    "plt.hold(True)\n",
    "sc = plt.scatter(np.ravel(uv[0, :]), np.ravel(uv[1, :]), s=20, c=pred_depth_error, edgecolors='none', norm=MidpointNormalize(midpoint=0.), cmap='RdYlGn')\n",
    "plt.colorbar(sc)\n",
    "plt.xlim(0, image.shape[1])\n",
    "plt.ylim(image.shape[0], 0)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "ax = plt.subplot(3, 2, 6)\n",
    "ax.set_title(\"INS PC - Pred Error (Rel. Mag.) [Pred - GT]\", fontsize=16)\n",
    "plt.imshow(image)\n",
    "plt.hold(True)\n",
    "sc = plt.scatter(np.ravel(uv[0, :]), np.ravel(uv[1, :]), s=20, c=np.abs(pred_depth_error/depth),\n",
    "                 edgecolors='none', cmap='Reds')\n",
    "plt.colorbar(sc)\n",
    "plt.xlim(0, image.shape[1])\n",
    "plt.ylim(image.shape[0], 0)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.savefig('result_imgs/' + str(timestamp_img) + 'results.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
