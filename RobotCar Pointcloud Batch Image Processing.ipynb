{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.interpolate as interp\n",
    "from scipy.ndimage import map_coordinates\n",
    "\n",
    "from robotcar.python.camera_model import CameraModel\n",
    "from robotcar.python.transform import build_se3_transform\n",
    "from robotcar.python.image import load_image\n",
    "from robotcar.python.interpolate_poses import interpolate_vo_poses, interpolate_ins_poses\n",
    "\n",
    "from monodepth.utils.evaluation_utils import compute_errors\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import shutil\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidpointNormalize(colors.Normalize):\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        colors.Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        # I'm ignoring masked values and all kinds of edge cases to make a\n",
    "        # simple example...\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Width and height of ground truth\n",
    "height = 960\n",
    "width = 1280\n",
    "\n",
    "def convert_disps_to_depths(pred_disp, height, width):\n",
    "\n",
    "    pred_disp = width * cv2.resize(pred_disp, (width, height), interpolation=cv2.INTER_LINEAR)\n",
    "    pred_depths = 983.044006 * 0.24 / pred_disp\n",
    "    return pred_depths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = '/media/psf/Data/Downloads/2014-12-05-11-09-10/2014-12-05-11-09-10_stereo_left_02/2014-12-05-11-09-10/stereo/left/'\n",
    "extrinsics_dir = 'robotcar/extrinsics/'\n",
    "models_dir = 'robotcar/models/'\n",
    "lidar_dir = '/media/psf/Data/Downloads/2014-12-05-11-09-10/2014-12-05-11-09-10_ldmrs/ldmrs/'\n",
    "\n",
    "lidar = 'ldmrs'\n",
    "\n",
    "vo_poses_file = '/media/psf/Data/Downloads/2014-12-05-11-09-10/2014-12-05-11-09-10_vo/vo/vo.csv'\n",
    "ins_poses_file = '/media/psf/Data/Downloads/2014-12-05-11-09-10/2014-12-05-11-09-10_gps/gps/ins.csv'\n",
    "\n",
    "test_image_dir = 'test_images'\n",
    "\n",
    "pred_disparities_file = 'test_images/disparities.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which image(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_index_start = 10050\n",
    "img_index_stop = 12000\n",
    "img_index_step = 100\n",
    "\n",
    "# micro!!s history for pointcloud generation\n",
    "time_minus = 10000000\n",
    "time_plus = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera and LIDAR Extrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CameraModel(models_dir, image_dir)\n",
    "\n",
    "extrinsics_path = os.path.join(extrinsics_dir, model.camera + '.txt')\n",
    "with open(extrinsics_path) as extrinsics_file:\n",
    "    extrinsics = [float(x) for x in next(extrinsics_file).split(' ')]\n",
    "\n",
    "G_camera_vehicle = build_se3_transform(extrinsics)\n",
    "\n",
    "with open(os.path.join(extrinsics_dir, lidar + '.txt')) as extrinsics_file:\n",
    "    extrinsics = next(extrinsics_file)\n",
    "G_posesource_laser = build_se3_transform([float(x) for x in extrinsics.split(' ')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Images and Save to test folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create/clear test_images folder and create filenames file\n",
    "if os.path.exists(test_image_dir):\n",
    "    shutil.rmtree(test_image_dir) \n",
    "os.makedirs(test_image_dir)\n",
    "\n",
    "with open(test_image_dir + '/test_images.txt', \"a+\") as filenames_file:\n",
    "    \n",
    "    for img_index in range(img_index_start, img_index_stop, img_index_step):\n",
    "        timestamps_path = os.path.join(image_dir, os.pardir, model.camera + '.timestamps')\n",
    "        if not os.path.isfile(timestamps_path):\n",
    "            timestamps_path = os.path.join(image_dir, os.pardir, os.pardir, model.camera + '.timestamps')\n",
    "\n",
    "        with open(timestamps_path) as timestamps_file:\n",
    "            for i, line in enumerate(timestamps_file):\n",
    "                if i == img_index:\n",
    "                    timestamp_img = int(line.split(' ')[0])\n",
    "\n",
    "        image_path = os.path.join(image_dir, str(timestamp_img) + '.png')\n",
    "        image = load_image(image_path, model)\n",
    "        img = Image.fromarray(image)\n",
    "        img.save('test_images/' + str(timestamp_img) + '.png')\n",
    "\n",
    "        # Append to filenames file\n",
    "        if img_index == img_index_start:\n",
    "            filenames_file.write(str(timestamp_img) + '.png')\n",
    "        else:\n",
    "            filenames_file.write('\\n' + str(timestamp_img) + '.png')\n",
    "filenames_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Monodept] Get Predictions from Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now testing 20 files\n",
      "step 0 from 20\n",
      "step 1 from 20\n",
      "step 2 from 20\n",
      "step 3 from 20\n",
      "step 4 from 20\n",
      "step 5 from 20\n",
      "step 6 from 20\n",
      "step 7 from 20\n",
      "step 8 from 20\n",
      "step 9 from 20\n",
      "step 10 from 20\n",
      "step 11 from 20\n",
      "step 12 from 20\n",
      "step 13 from 20\n",
      "step 14 from 20\n",
      "step 15 from 20\n",
      "step 16 from 20\n",
      "step 17 from 20\n",
      "step 18 from 20\n",
      "step 19 from 20\n",
      "done.\n",
      "writing disparities.\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "!python monodepth/monodepth_main.py --mode test --data_path test_images/ --filenames_file test_images/test_images.txt --log_directory log/ --checkpoint_path monodepth/model_kitti/model_kitti.ckpt --output_directory test_images/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Monodepth] Convert predicted disparities to depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 256, 512)\n"
     ]
    }
   ],
   "source": [
    "pred_disparities = np.load(pred_disparities_file)\n",
    "\n",
    "print(pred_disparities.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Pointclouds and save ground truth\n",
    "## TODO save ground truth to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161, 'LIDAR Scans found')\n",
      "VO Pointcloud build\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "robotcar/python/interpolate_poses.py:141: RuntimeWarning: divide by zero encountered in divide\n",
      "  (pose_timestamps[upper_indices] - pose_timestamps[lower_indices])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INS Pointcloud build\n",
      "Sparse Pointcloud build\n",
      "(161, 'LIDAR Scans found')\n",
      "VO Pointcloud build\n",
      "INS Pointcloud build\n",
      "Sparse Pointcloud build\n",
      "(161, 'LIDAR Scans found')\n",
      "VO Pointcloud build\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-baf9119876bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mG_camera_posesource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG_camera_vehicle\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbuild_se3_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextrinsics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mposes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpolate_ins_poses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_poses_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mpointcloud_ins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/parallels/cse291/depth_estimation/robotcar/python/interpolate_poses.pyc\u001b[0m in \u001b[0;36minterpolate_ins_poses\u001b[0;34m(ins_path, pose_timestamps, origin_timestamp)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mabs_poses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs_poses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0minterpolate_poses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_timestamps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs_poses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpose_timestamps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin_timestamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/parallels/cse291/depth_estimation/robotcar/python/interpolate_poses.pyc\u001b[0m in \u001b[0;36minterpolate_poses\u001b[0;34m(pose_timestamps, abs_poses, requested_timestamps, origin_timestamp)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pose timestamps must be in ascending order'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mabs_quaternions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mso3_to_quaternion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpose\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0mabs_positions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpose\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "timestamps_path = os.path.join(lidar_dir, os.pardir, lidar + '.timestamps')\n",
    "\n",
    "# Loop trough image indices\n",
    "for img_index in range(img_index_start, img_index_stop, img_index_step):\n",
    "    \n",
    "    # Get current image timestamp\n",
    "    timestamps_path = os.path.join(image_dir, os.pardir, model.camera + '.timestamps')\n",
    "    if not os.path.isfile(timestamps_path):\n",
    "        timestamps_path = os.path.join(image_dir, os.pardir, os.pardir, model.camera + '.timestamps')\n",
    "\n",
    "    with open(timestamps_path) as timestamps_file:\n",
    "        for i, line in enumerate(timestamps_file):\n",
    "            if i == img_index:\n",
    "                timestamp_img = int(line.split(' ')[0])\n",
    "\n",
    "    timestamps = []\n",
    "    with open(timestamps_path) as timestamps_file:\n",
    "        for line in timestamps_file:\n",
    "            timestamp = int(line.split(' ')[0])\n",
    "            if (timestamp_img-time_minus) <= timestamp <= (timestamp_img+time_plus):\n",
    "                timestamps.append(timestamp)\n",
    "\n",
    "    print(len(timestamps), \"LIDAR Scans found\")\n",
    "\n",
    "    if len(timestamps) == 0:\n",
    "        raise ValueError(\"No LIDAR data in the given time bracket.\")\n",
    "\n",
    "    # VO Pointcloud\n",
    "    \n",
    "    # sensor is VO, which is located at the main vehicle frame\n",
    "    poses = interpolate_vo_poses(vo_poses_file, timestamps, timestamp_img)\n",
    "\n",
    "    pointcloud_vo = np.array([[0], [0], [0], [0]])\n",
    "\n",
    "    for i in range(0, len(poses)):\n",
    "        scan_path = os.path.join(lidar_dir, str(timestamps[i]) + '.bin')\n",
    "        if not os.path.isfile(scan_path):\n",
    "            continue\n",
    "\n",
    "        scan_file = open(scan_path)\n",
    "        scan = np.fromfile(scan_file, np.double)\n",
    "        scan_file.close()\n",
    "        scan = scan.reshape((len(scan) // 3, 3)).transpose()\n",
    "        scan = np.dot(np.dot(poses[i], G_posesource_laser), np.vstack([scan, np.ones((1, scan.shape[1]))]))\n",
    "        pointcloud_vo = np.hstack([pointcloud_vo, scan])\n",
    "\n",
    "    pointcloud_vo = pointcloud_vo[:, 1:]\n",
    "    pointcloud_vo = np.dot(G_camera_vehicle, pointcloud_vo)\n",
    "    print(\"VO Pointcloud build\")\n",
    "    \n",
    "    # INS Pointcloud\n",
    "    \n",
    "    with open(os.path.join(extrinsics_dir, 'ins.txt')) as extrinsics_file:\n",
    "        extrinsics = next(extrinsics_file)\n",
    "        G_posesource_laser = np.linalg.solve(build_se3_transform([float(x) for x in extrinsics.split(' ')]),\n",
    "                                             G_posesource_laser)\n",
    "        G_camera_posesource = G_camera_vehicle * build_se3_transform([float(x) for x in extrinsics.split(' ')])\n",
    "\n",
    "    poses = interpolate_ins_poses(ins_poses_file, timestamps, timestamp_img)\n",
    "\n",
    "    pointcloud_ins = np.array([[0], [0], [0], [0]])\n",
    "\n",
    "    for i in range(0, len(poses)):\n",
    "        scan_path = os.path.join(lidar_dir, str(timestamps[i]) + '.bin')\n",
    "        if not os.path.isfile(scan_path):\n",
    "            continue\n",
    "\n",
    "        scan_file = open(scan_path)\n",
    "        scan = np.fromfile(scan_file, np.double)\n",
    "        scan_file.close()\n",
    "        scan = scan.reshape((len(scan) // 3, 3)).transpose()\n",
    "        scan = np.dot(np.dot(poses[i], G_posesource_laser), np.vstack([scan, np.ones((1, scan.shape[1]))]))\n",
    "        pointcloud_ins = np.hstack([pointcloud_ins, scan])\n",
    "\n",
    "    pointcloud_ins = pointcloud_ins[:, 1:]\n",
    "    pointcloud_ins = np.dot(G_camera_posesource, pointcloud_ins)\n",
    "    print(\"INS Pointcloud build\")\n",
    "\n",
    "    # Sparse Local Pointcloud\n",
    "    \n",
    "    with open(os.path.join(extrinsics_dir, 'ins.txt')) as extrinsics_file:\n",
    "        extrinsics = next(extrinsics_file)\n",
    "        G_posesource_laser = np.linalg.solve(build_se3_transform([float(x) for x in extrinsics.split(' ')]),\n",
    "                                             G_posesource_laser)\n",
    "        G_camera_posesource = G_camera_vehicle * build_se3_transform([float(x) for x in extrinsics.split(' ')])\n",
    "\n",
    "    poses = interpolate_ins_poses(ins_poses_file, timestamps, timestamp_img)\n",
    "\n",
    "    pointcloud_ins = np.array([[0], [0], [0], [0]])\n",
    "\n",
    "    for i in range(0, len(poses)):\n",
    "        scan_path = os.path.join(lidar_dir, str(timestamps[i]) + '.bin')\n",
    "        if not os.path.isfile(scan_path):\n",
    "            continue\n",
    "\n",
    "        scan_file = open(scan_path)\n",
    "        scan = np.fromfile(scan_file, np.double)\n",
    "        scan_file.close()\n",
    "        scan = scan.reshape((len(scan) // 3, 3)).transpose()\n",
    "        scan = np.dot(np.dot(poses[i], G_posesource_laser), np.vstack([scan, np.ones((1, scan.shape[1]))]))\n",
    "        pointcloud_ins = np.hstack([pointcloud_ins, scan])\n",
    "\n",
    "    pointcloud_ins = pointcloud_ins[:, 1:]\n",
    "    pointcloud_ins = np.dot(G_camera_posesource, pointcloud_ins)\n",
    "\n",
    "    print(\"Sparse Pointcloud build\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Test Result with Ground Truth\n",
    "## TODO implement for multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_disparities = np.load('test_images/test_disp.npy')\n",
    "\n",
    "pred_depth = convert_disps_to_depths(pred_disparities, 960, 1280)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Error Magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(16,20))\n",
    "\n",
    "# Sparse Map\n",
    "ax = plt.subplot(3, 2, 1)\n",
    "ax.set_title(\"Local PC - Pred Error (m) [Pred - GT]\", fontsize=16)\n",
    "uv, depth = model.project(local_pointcloud, image.shape)\n",
    "\n",
    "uv = np.array(uv)\n",
    "depth = np.array(depth)\n",
    "mask = ((uv[0,:] < 1279) & (uv[1,:] < 959) & (depth < 80))\n",
    "depth = depth[mask]\n",
    "uv = uv[:, mask]\n",
    "\n",
    "gt_img = np.zeros((960, 1280))\n",
    "coords = uv.transpose().astype(int)\n",
    "gt_img[coords[:,1],coords[:,0]] = depth\n",
    "compute_errors(gt_img[gt_img != 0], pred_depth[gt_img != 0])\n",
    "abs_rel, sq_rel, rms, log_rms, a1, a2, a3 = compute_errors(gt_img[gt_img != 0], pred_depth[gt_img != 0])\n",
    "print(\"Errors for Local LIDAR:\")\n",
    "print(\"{:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}\".format('abs_rel', 'sq_rel', 'rms', 'log_rms', 'a1', 'a2', 'a3'))\n",
    "print(\"{:10.4f}, {:10.4f}, {:10.3f}, {:10.3f}, {:10.3f}, {:10.3f}, {:10.3f}\".format(abs_rel.mean(), sq_rel.mean(), rms.mean(), log_rms.mean(), a1.mean(), a2.mean(), a3.mean()))\n",
    "\n",
    "pixels = uv.transpose()\n",
    "# 1200 x 960\n",
    "pred_depth_pixels = []\n",
    "pred_depth_error = []\n",
    "i = 0\n",
    "for pixel in pixels:\n",
    "    # Sparse\n",
    "    pred_depth_pixels.append(pred_depth[int(round(pixel[1]))][int(round(pixel[0]))])\n",
    "    pred_depth_error.append(pred_depth[int(round(pixel[1]))][int(round(pixel[0]))] - depth[i])\n",
    "    i += 1\n",
    "\n",
    "# Limit coordinates to image size\n",
    "pred_depth_pixels = np.array(pred_depth_pixels)\n",
    "pred_depth_error = np.array(pred_depth_error)\n",
    "mask = (pred_depth_pixels < 80)\n",
    "depth = depth[mask]\n",
    "uv = uv[:, mask]\n",
    "pred_depth_error = pred_depth_error[mask]\n",
    "pred_depth_pixels = pred_depth_pixels[mask]\n",
    "    \n",
    "plt.imshow(image)\n",
    "plt.hold(True)\n",
    "sc = plt.scatter(np.ravel(uv[0, :]), np.ravel(uv[1, :]), s=20, c=pred_depth_error,\n",
    "                 edgecolors='none', norm=MidpointNormalize(midpoint=0.) , cmap='RdYlGn')\n",
    "plt.colorbar(sc)\n",
    "plt.xlim(0, image.shape[1])\n",
    "plt.ylim(image.shape[0], 0)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "ax = plt.subplot(3, 2, 2)\n",
    "ax.set_title(\"Local PC - Pred Error (Rel. Mag.) [Pred - GT]\", fontsize=16)\n",
    "plt.imshow(image)\n",
    "plt.hold(True)\n",
    "sc = plt.scatter(np.ravel(uv[0, :]), np.ravel(uv[1, :]), s=20, c=np.abs(pred_depth_error/depth),\n",
    "                 edgecolors='none', cmap='Reds')\n",
    "plt.colorbar(sc)\n",
    "plt.xlim(0, image.shape[1])\n",
    "plt.ylim(image.shape[0], 0)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "ax = plt.subplot(3, 2, 3)\n",
    "ax.set_title(\"VO PC - Pred Error (m) [Pred - GT]\", fontsize=16)\n",
    "uv, depth = model.project(pointcloud_vo, image.shape)\n",
    "\n",
    "# Limit coordinates to image size\n",
    "uv = np.array(uv)\n",
    "depth = np.array(depth)\n",
    "mask = ((uv[0,:] < 1279) & (uv[1,:] < 959) & (depth < 80))\n",
    "depth = depth[mask]\n",
    "uv = uv[:, mask]\n",
    "\n",
    "gt_img = np.zeros((960, 1280))\n",
    "coords = uv.transpose().astype(int)\n",
    "gt_img[coords[:,1],coords[:,0]] = depth\n",
    "compute_errors(gt_img[gt_img != 0], pred_depth[gt_img != 0])\n",
    "abs_rel, sq_rel, rms, log_rms, a1, a2, a3 = compute_errors(gt_img[gt_img != 0], pred_depth[gt_img != 0])\n",
    "print(\"Errors for INS LIDAR:\")\n",
    "print(\"{:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}\".format('abs_rel', 'sq_rel', 'rms', 'log_rms', 'a1', 'a2', 'a3'))\n",
    "print(\"{:10.4f}, {:10.4f}, {:10.3f}, {:10.3f}, {:10.3f}, {:10.3f}, {:10.3f}\".format(abs_rel.mean(), sq_rel.mean(), rms.mean(), log_rms.mean(), a1.mean(), a2.mean(), a3.mean()))\n",
    "\n",
    "pixels = uv.transpose()\n",
    "# 1200 x 960\n",
    "pred_depth_pixels = []\n",
    "pred_depth_error = []\n",
    "i = 0\n",
    "for pixel in pixels:\n",
    "    # Sparse\n",
    "    pred_depth_pixels.append(pred_depth[int(round(pixel[1]))][int(round(pixel[0]))])\n",
    "    pred_depth_error.append(pred_depth[int(round(pixel[1]))][int(round(pixel[0]))] - depth[i])\n",
    "    i += 1\n",
    "\n",
    "# Limit coordinates to image size\n",
    "pred_depth_pixels = np.array(pred_depth_pixels)\n",
    "pred_depth_error = np.array(pred_depth_error)\n",
    "mask = (pred_depth_pixels < 80)\n",
    "depth = depth[mask]\n",
    "uv = uv[:, mask]\n",
    "pred_depth_error = pred_depth_error[mask]\n",
    "pred_depth_pixels = pred_depth_pixels[mask]\n",
    "    \n",
    "plt.imshow(image)\n",
    "plt.hold(True)\n",
    "sc = plt.scatter(np.ravel(uv[0, :]), np.ravel(uv[1, :]), s=20, c=pred_depth_error, norm=MidpointNormalize(midpoint=0.), cmap='RdYlGn',\n",
    "                 edgecolors='none')\n",
    "plt.colorbar(sc)\n",
    "plt.xlim(0, image.shape[1])\n",
    "plt.ylim(image.shape[0], 0)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "ax = plt.subplot(3, 2, 4)\n",
    "ax.set_title(\"VO PC - Pred Error (Rel. Mag.) [Pred - GT]\", fontsize=16)\n",
    "plt.imshow(image)\n",
    "plt.hold(True)\n",
    "sc = plt.scatter(np.ravel(uv[0, :]), np.ravel(uv[1, :]), s=20, c=np.abs(pred_depth_error/depth),\n",
    "                 edgecolors='none', cmap='Reds')\n",
    "plt.colorbar(sc)\n",
    "plt.xlim(0, image.shape[1])\n",
    "plt.ylim(image.shape[0], 0)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "ax = plt.subplot(3, 2, 5)\n",
    "ax.set_title(\"INS PC - Pred Error (m) [Pred - GT]\", fontsize=16)\n",
    "uv, depth = model.project(pointcloud_ins, image.shape)\n",
    "\n",
    "# Limit coordinates to image size\n",
    "uv = np.array(uv)\n",
    "depth = np.array(depth)\n",
    "mask = ((uv[0,:] < 1279) & (uv[1,:] < 959) & (depth < 80))\n",
    "depth = depth[mask]\n",
    "uv = uv[:, mask]\n",
    "\n",
    "gt_img = np.zeros((960, 1280))\n",
    "coords = uv.transpose().astype(int)\n",
    "gt_img[coords[:,1],coords[:,0]] = depth\n",
    "compute_errors(gt_img[gt_img != 0], pred_depth[gt_img != 0])\n",
    "abs_rel, sq_rel, rms, log_rms, a1, a2, a3 = compute_errors(gt_img[gt_img != 0], pred_depth[gt_img != 0])\n",
    "print(\"Errors for VO LIDAR:\")\n",
    "print(\"{:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}\".format('abs_rel', 'sq_rel', 'rms', 'log_rms', 'a1', 'a2', 'a3'))\n",
    "print(\"{:10.4f}, {:10.4f}, {:10.3f}, {:10.3f}, {:10.3f}, {:10.3f}, {:10.3f}\".format(abs_rel.mean(), sq_rel.mean(), rms.mean(), log_rms.mean(), a1.mean(), a2.mean(), a3.mean()))\n",
    "\n",
    "pixels = uv.transpose()\n",
    "# 1200 x 960\n",
    "pred_depth_pixels = []\n",
    "pred_depth_error = []\n",
    "i = 0\n",
    "for pixel in pixels:\n",
    "    # Sparse\n",
    "    pred_depth_pixels.append(pred_depth[int(round(pixel[1]))][int(round(pixel[0]))])\n",
    "    pred_depth_error.append(pred_depth[int(round(pixel[1]))][int(round(pixel[0]))] - depth[i])\n",
    "    i += 1\n",
    "\n",
    "# Limit coordinates to image size\n",
    "pred_depth_pixels = np.array(pred_depth_pixels)\n",
    "pred_depth_error = np.array(pred_depth_error)\n",
    "mask = (pred_depth_pixels < 80)\n",
    "depth = depth[mask]\n",
    "uv = uv[:, mask]\n",
    "pred_depth_error = pred_depth_error[mask]\n",
    "pred_depth_pixels = pred_depth_pixels[mask]\n",
    "    \n",
    "plt.imshow(image)\n",
    "plt.hold(True)\n",
    "sc = plt.scatter(np.ravel(uv[0, :]), np.ravel(uv[1, :]), s=20, c=pred_depth_error, edgecolors='none', norm=MidpointNormalize(midpoint=0.), cmap='RdYlGn')\n",
    "plt.colorbar(sc)\n",
    "plt.xlim(0, image.shape[1])\n",
    "plt.ylim(image.shape[0], 0)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "ax = plt.subplot(3, 2, 6)\n",
    "ax.set_title(\"INS PC - Pred Error (Rel. Mag.) [Pred - GT]\", fontsize=16)\n",
    "plt.imshow(image)\n",
    "plt.hold(True)\n",
    "sc = plt.scatter(np.ravel(uv[0, :]), np.ravel(uv[1, :]), s=20, c=np.abs(pred_depth_error/depth),\n",
    "                 edgecolors='none', cmap='Reds')\n",
    "plt.colorbar(sc)\n",
    "plt.xlim(0, image.shape[1])\n",
    "plt.ylim(image.shape[0], 0)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.savefig('result_imgs/' + str(timestamp_img) + 'results.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
